{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn7ialO2nns2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/final_reports_2016-23_cons_2024-12-24.csv', sep=';', quotechar='\"')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "9f761fdc",
        "outputId": "f55a2e57-ae2c-444a-c84a-3528370a425e"
      },
      "source": [
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       NtsbNo EventType    Mkey             EventDate           City  \\\n",
              "0  ERA24LA084       ACC  193603  2023-12-31T15:13:00Z        Midland   \n",
              "1  ERA24LA079       ACC  193587  2023-12-30T15:04:00Z  Daytona Beach   \n",
              "2  CEN24LA081       ACC  193605  2023-12-29T15:27:00Z       Beaumont   \n",
              "3  WPR24LA062       ACC  193584  2023-12-28T10:57:00Z    Lake Havasu   \n",
              "4  WPR24LA061       ACC  193576  2023-12-26T13:21:00Z       Prescott   \n",
              "\n",
              "        State        Country ReportNo                  N#  \\\n",
              "0    Virginia  United States      NaN               N37GA   \n",
              "1     Florida  United States      NaN  N828AK, FA3XNWMRAN   \n",
              "2       Texas  United States      NaN               N71MS   \n",
              "3  California  United States      NaN              N312PR   \n",
              "4     Arizona  United States      NaN               N29TT   \n",
              "\n",
              "           SerialNumber  ...  WeatherCondition                 Operator  \\\n",
              "0                 004CE  ...               VMC                      NaN   \n",
              "1  1689, 163DF81001N020  ...               VMC   Tunica Helicopters LLC   \n",
              "2                 7452C  ...               VMC  TAF AERIAL SERVICES LLC   \n",
              "3                  1127  ...               VMC                      NaN   \n",
              "4                   451  ...               VMC                      NaN   \n",
              "\n",
              "  BroadPhaseofFlight ReportStatus RepGenFlag MostRecentReportType  \\\n",
              "0            Landing    Completed        NaN                Final   \n",
              "1           Approach    Completed        NaN                Final   \n",
              "2            Landing    Completed        NaN                Final   \n",
              "3            Landing    Completed        NaN                Final   \n",
              "4            Landing    Completed        NaN                Final   \n",
              "\n",
              "                                       DocketUrl  \\\n",
              "0  https://data.ntsb.gov/Docket?ProjectID=193603   \n",
              "1                                            NaN   \n",
              "2  https://data.ntsb.gov/Docket?ProjectID=193605   \n",
              "3  https://data.ntsb.gov/Docket?ProjectID=193584   \n",
              "4  https://data.ntsb.gov/Docket?ProjectID=193576   \n",
              "\n",
              "                                           ReportUrl  \\\n",
              "0  https://data.ntsb.gov/carol-repgen/api/Aviatio...   \n",
              "1  https://data.ntsb.gov/carol-repgen/api/Aviatio...   \n",
              "2  https://data.ntsb.gov/carol-repgen/api/Aviatio...   \n",
              "3  https://data.ntsb.gov/carol-repgen/api/Aviatio...   \n",
              "4  https://data.ntsb.gov/carol-repgen/api/Aviatio...   \n",
              "\n",
              "                                            rep_text  rep_num_jsg  \n",
              "0  Page 1 of 5\\nAviation Investigation Final Repo...   ERA24LA084  \n",
              "1  Page 1 of 7\\nAviation Investigation Final Repo...   ERA24LA079  \n",
              "2  Page 1 of 5\\nAviation Investigation Final Repo...   CEN24LA081  \n",
              "3  Page 1 of 5\\nAviation Investigation Final Repo...   WPR24LA062  \n",
              "4  Page 1 of 8\\nAviation Investigation Final Repo...   WPR24LA061  \n",
              "\n",
              "[5 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-916a3caf-9084-45ab-9069-f090a58bcc13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NtsbNo</th>\n",
              "      <th>EventType</th>\n",
              "      <th>Mkey</th>\n",
              "      <th>EventDate</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Country</th>\n",
              "      <th>ReportNo</th>\n",
              "      <th>N#</th>\n",
              "      <th>SerialNumber</th>\n",
              "      <th>...</th>\n",
              "      <th>WeatherCondition</th>\n",
              "      <th>Operator</th>\n",
              "      <th>BroadPhaseofFlight</th>\n",
              "      <th>ReportStatus</th>\n",
              "      <th>RepGenFlag</th>\n",
              "      <th>MostRecentReportType</th>\n",
              "      <th>DocketUrl</th>\n",
              "      <th>ReportUrl</th>\n",
              "      <th>rep_text</th>\n",
              "      <th>rep_num_jsg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERA24LA084</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193603</td>\n",
              "      <td>2023-12-31T15:13:00Z</td>\n",
              "      <td>Midland</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N37GA</td>\n",
              "      <td>004CE</td>\n",
              "      <td>...</td>\n",
              "      <td>VMC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Landing</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Final</td>\n",
              "      <td>https://data.ntsb.gov/Docket?ProjectID=193603</td>\n",
              "      <td>https://data.ntsb.gov/carol-repgen/api/Aviatio...</td>\n",
              "      <td>Page 1 of 5\\nAviation Investigation Final Repo...</td>\n",
              "      <td>ERA24LA084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERA24LA079</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193587</td>\n",
              "      <td>2023-12-30T15:04:00Z</td>\n",
              "      <td>Daytona Beach</td>\n",
              "      <td>Florida</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N828AK, FA3XNWMRAN</td>\n",
              "      <td>1689, 163DF81001N020</td>\n",
              "      <td>...</td>\n",
              "      <td>VMC</td>\n",
              "      <td>Tunica Helicopters LLC</td>\n",
              "      <td>Approach</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://data.ntsb.gov/carol-repgen/api/Aviatio...</td>\n",
              "      <td>Page 1 of 7\\nAviation Investigation Final Repo...</td>\n",
              "      <td>ERA24LA079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CEN24LA081</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193605</td>\n",
              "      <td>2023-12-29T15:27:00Z</td>\n",
              "      <td>Beaumont</td>\n",
              "      <td>Texas</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N71MS</td>\n",
              "      <td>7452C</td>\n",
              "      <td>...</td>\n",
              "      <td>VMC</td>\n",
              "      <td>TAF AERIAL SERVICES LLC</td>\n",
              "      <td>Landing</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Final</td>\n",
              "      <td>https://data.ntsb.gov/Docket?ProjectID=193605</td>\n",
              "      <td>https://data.ntsb.gov/carol-repgen/api/Aviatio...</td>\n",
              "      <td>Page 1 of 5\\nAviation Investigation Final Repo...</td>\n",
              "      <td>CEN24LA081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WPR24LA062</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193584</td>\n",
              "      <td>2023-12-28T10:57:00Z</td>\n",
              "      <td>Lake Havasu</td>\n",
              "      <td>California</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N312PR</td>\n",
              "      <td>1127</td>\n",
              "      <td>...</td>\n",
              "      <td>VMC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Landing</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Final</td>\n",
              "      <td>https://data.ntsb.gov/Docket?ProjectID=193584</td>\n",
              "      <td>https://data.ntsb.gov/carol-repgen/api/Aviatio...</td>\n",
              "      <td>Page 1 of 5\\nAviation Investigation Final Repo...</td>\n",
              "      <td>WPR24LA062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WPR24LA061</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193576</td>\n",
              "      <td>2023-12-26T13:21:00Z</td>\n",
              "      <td>Prescott</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N29TT</td>\n",
              "      <td>451</td>\n",
              "      <td>...</td>\n",
              "      <td>VMC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Landing</td>\n",
              "      <td>Completed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Final</td>\n",
              "      <td>https://data.ntsb.gov/Docket?ProjectID=193576</td>\n",
              "      <td>https://data.ntsb.gov/carol-repgen/api/Aviatio...</td>\n",
              "      <td>Page 1 of 8\\nAviation Investigation Final Repo...</td>\n",
              "      <td>WPR24LA061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-916a3caf-9084-45ab-9069-f090a58bcc13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-916a3caf-9084-45ab-9069-f090a58bcc13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-916a3caf-9084-45ab-9069-f090a58bcc13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-26f148b1-1a61-4fa9-850d-ff200ecfd577\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26f148b1-1a61-4fa9-850d-ff200ecfd577')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-26f148b1-1a61-4fa9-850d-ff200ecfd577 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"elihoole/asrs-aviation-reports\")"
      ],
      "metadata": {
        "id": "EjLrkqNmppmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "a822792f",
        "outputId": "08c103e9-59b1-4207-b9ba-361d249a39d4"
      },
      "source": [
        "# Convert the Hugging Face dataset 'ds' to a pandas DataFrame\n",
        "ds_df = ds['train'].to_pandas()\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "print(\"First 5 rows of the 'ds' dataset (as DataFrame):\")\n",
        "display(ds_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the 'ds' dataset (as DataFrame):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  acn_num_ACN Time_Date Time.1_Local Time Of Day Place_Locale Reference  \\\n",
              "0     1574675    201808                0601-1200            SNA.Airport   \n",
              "1     1224894    201412                0601-1200            MSY.Airport   \n",
              "2     1134202    201312                1201-1800              ZZZ.ARTCC   \n",
              "3     1222074    201411                1201-1800            CWA.Airport   \n",
              "4     1733019    202003                1801-2400              ZDV.ARTCC   \n",
              "\n",
              "  Place.1_State Reference Place.2_Relative Position.Angle.Radial  \\\n",
              "0                      CA                                          \n",
              "1                      LA                                          \n",
              "2                      US                                          \n",
              "3                      WI                                          \n",
              "4                      CO                                          \n",
              "\n",
              "  Place.3_Relative Position.Distance.Nautical Miles  \\\n",
              "0                                                     \n",
              "1                                                     \n",
              "2                                                     \n",
              "3                                              20.0   \n",
              "4                                                     \n",
              "\n",
              "  Place.4_Altitude.AGL.Single Value Place.5_Altitude.MSL.Single Value  \\\n",
              "0                                                              5000.0   \n",
              "1                            1000.0                                     \n",
              "2                                                              2600.0   \n",
              "3                                                              4000.0   \n",
              "4                                                             32000.0   \n",
              "\n",
              "  Environment_Flight Conditions  ...  \\\n",
              "0                                ...   \n",
              "1                           VMC  ...   \n",
              "2                           IMC  ...   \n",
              "3                                ...   \n",
              "4                                ...   \n",
              "\n",
              "                                Events.3_Detector Events.4_When Detected  \\\n",
              "0  Person Air Traffic Control; Person Flight Crew              In-flight   \n",
              "1                              Person Flight Crew              In-flight   \n",
              "2                              Person Flight Crew              In-flight   \n",
              "3                              Person Flight Crew              In-flight   \n",
              "4                              Person Flight Crew              In-flight   \n",
              "\n",
              "                                     Events.5_Result  \\\n",
              "0  Air Traffic Control Issued New Clearance; Flig...   \n",
              "1                      General None Reported / Taken   \n",
              "2  Air Traffic Control Provided Assistance; Air T...   \n",
              "3  Flight Crew Became Reoriented; General Mainten...   \n",
              "4  Air Traffic Control Issued New Clearance; Flig...   \n",
              "\n",
              "  Assessments_Contributing Factors / Situations Assessments.1_Primary Problem  \\\n",
              "0                                 Human Factors                 Human Factors   \n",
              "1                                 Human Factors                 Human Factors   \n",
              "2   Human Factors; Aircraft; Procedure; Weather                      Aircraft   \n",
              "3                                      Aircraft                      Aircraft   \n",
              "4                   Airspace Structure; Weather                       Weather   \n",
              "\n",
              "                                  Report 1_Narrative Report 1.1_Callback  \\\n",
              "0  SNA RNP-Z to Runway 20R. The FMC was properly ...                       \n",
              "1  On base to final turn to runway 1 in MSY at ap...                       \n",
              "2  I climbed to my filed altitude of 5;000 FT; an...                       \n",
              "3  I had my pitot heat checked prior to winter an...                       \n",
              "4  At 32000 ft. just north of PUB the aircraft ex...                       \n",
              "\n",
              "                                  Report 2_Narrative Report 2.1_Callback  \\\n",
              "0  We were cleared for the RNP RNAV Z 20R Approac...                       \n",
              "1                                                                          \n",
              "2                                                                          \n",
              "3                                                                          \n",
              "4                                                                          \n",
              "\n",
              "                                 Report 1.2_Synopsis  \n",
              "0  B737-700 flight crew reported failing to make ...  \n",
              "1  Captain reports sighting of a drone at 1;000 f...  \n",
              "2  SR22 pilot became disoriented on approach in I...  \n",
              "3  BE58 pilot experiences pitot heat failure desc...  \n",
              "4  B737 First Officer reported unexpected moderat...  \n",
              "\n",
              "[5 rows x 111 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a895582f-3c4b-463a-a485-5d2c39f8b8aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acn_num_ACN</th>\n",
              "      <th>Time_Date</th>\n",
              "      <th>Time.1_Local Time Of Day</th>\n",
              "      <th>Place_Locale Reference</th>\n",
              "      <th>Place.1_State Reference</th>\n",
              "      <th>Place.2_Relative Position.Angle.Radial</th>\n",
              "      <th>Place.3_Relative Position.Distance.Nautical Miles</th>\n",
              "      <th>Place.4_Altitude.AGL.Single Value</th>\n",
              "      <th>Place.5_Altitude.MSL.Single Value</th>\n",
              "      <th>Environment_Flight Conditions</th>\n",
              "      <th>...</th>\n",
              "      <th>Events.3_Detector</th>\n",
              "      <th>Events.4_When Detected</th>\n",
              "      <th>Events.5_Result</th>\n",
              "      <th>Assessments_Contributing Factors / Situations</th>\n",
              "      <th>Assessments.1_Primary Problem</th>\n",
              "      <th>Report 1_Narrative</th>\n",
              "      <th>Report 1.1_Callback</th>\n",
              "      <th>Report 2_Narrative</th>\n",
              "      <th>Report 2.1_Callback</th>\n",
              "      <th>Report 1.2_Synopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1574675</td>\n",
              "      <td>201808</td>\n",
              "      <td>0601-1200</td>\n",
              "      <td>SNA.Airport</td>\n",
              "      <td>CA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5000.0</td>\n",
              "      <td></td>\n",
              "      <td>...</td>\n",
              "      <td>Person Air Traffic Control; Person Flight Crew</td>\n",
              "      <td>In-flight</td>\n",
              "      <td>Air Traffic Control Issued New Clearance; Flig...</td>\n",
              "      <td>Human Factors</td>\n",
              "      <td>Human Factors</td>\n",
              "      <td>SNA RNP-Z to Runway 20R. The FMC was properly ...</td>\n",
              "      <td></td>\n",
              "      <td>We were cleared for the RNP RNAV Z 20R Approac...</td>\n",
              "      <td></td>\n",
              "      <td>B737-700 flight crew reported failing to make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1224894</td>\n",
              "      <td>201412</td>\n",
              "      <td>0601-1200</td>\n",
              "      <td>MSY.Airport</td>\n",
              "      <td>LA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1000.0</td>\n",
              "      <td></td>\n",
              "      <td>VMC</td>\n",
              "      <td>...</td>\n",
              "      <td>Person Flight Crew</td>\n",
              "      <td>In-flight</td>\n",
              "      <td>General None Reported / Taken</td>\n",
              "      <td>Human Factors</td>\n",
              "      <td>Human Factors</td>\n",
              "      <td>On base to final turn to runway 1 in MSY at ap...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Captain reports sighting of a drone at 1;000 f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1134202</td>\n",
              "      <td>201312</td>\n",
              "      <td>1201-1800</td>\n",
              "      <td>ZZZ.ARTCC</td>\n",
              "      <td>US</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2600.0</td>\n",
              "      <td>IMC</td>\n",
              "      <td>...</td>\n",
              "      <td>Person Flight Crew</td>\n",
              "      <td>In-flight</td>\n",
              "      <td>Air Traffic Control Provided Assistance; Air T...</td>\n",
              "      <td>Human Factors; Aircraft; Procedure; Weather</td>\n",
              "      <td>Aircraft</td>\n",
              "      <td>I climbed to my filed altitude of 5;000 FT; an...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>SR22 pilot became disoriented on approach in I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1222074</td>\n",
              "      <td>201411</td>\n",
              "      <td>1201-1800</td>\n",
              "      <td>CWA.Airport</td>\n",
              "      <td>WI</td>\n",
              "      <td></td>\n",
              "      <td>20.0</td>\n",
              "      <td></td>\n",
              "      <td>4000.0</td>\n",
              "      <td></td>\n",
              "      <td>...</td>\n",
              "      <td>Person Flight Crew</td>\n",
              "      <td>In-flight</td>\n",
              "      <td>Flight Crew Became Reoriented; General Mainten...</td>\n",
              "      <td>Aircraft</td>\n",
              "      <td>Aircraft</td>\n",
              "      <td>I had my pitot heat checked prior to winter an...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>BE58 pilot experiences pitot heat failure desc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1733019</td>\n",
              "      <td>202003</td>\n",
              "      <td>1801-2400</td>\n",
              "      <td>ZDV.ARTCC</td>\n",
              "      <td>CO</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>32000.0</td>\n",
              "      <td></td>\n",
              "      <td>...</td>\n",
              "      <td>Person Flight Crew</td>\n",
              "      <td>In-flight</td>\n",
              "      <td>Air Traffic Control Issued New Clearance; Flig...</td>\n",
              "      <td>Airspace Structure; Weather</td>\n",
              "      <td>Weather</td>\n",
              "      <td>At 32000 ft. just north of PUB the aircraft ex...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>B737 First Officer reported unexpected moderat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 111 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a895582f-3c4b-463a-a485-5d2c39f8b8aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a895582f-3c4b-463a-a485-5d2c39f8b8aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a895582f-3c4b-463a-a485-5d2c39f8b8aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a8106a3-e5ca-42f3-ae3d-aa7ef1a2dbfe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a8106a3-e5ca-42f3-ae3d-aa7ef1a2dbfe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a8106a3-e5ca-42f3-ae3d-aa7ef1a2dbfe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf007dfb"
      },
      "source": [
        "# Display the first few rows of the 'df' dataset for comparison\n",
        "print(\"\\nFirst 5 rows of the 'df' dataset:\")\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the two datasets\n"
      ],
      "metadata": {
        "id": "GbzOzHQT_aeb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "169b9695"
      },
      "source": [
        "# Add a 'source' column to each DataFrame\n",
        "df['source'] = 'NTSB'\n",
        "ds_df['source'] = 'ASRS'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b6b23b8"
      },
      "source": [
        "# Define column renaming maps for better consistency\n",
        "# Renaming for df (NTSB data)\n",
        "nts_df_rename_map = {\n",
        "    'NtsbNo': 'ReportID',\n",
        "    'EventDate': 'EventDate',\n",
        "    'Make': 'AircraftMake',\n",
        "    'Model': 'AircraftModel',\n",
        "    'EventType': 'EventType',\n",
        "    'ProbableCause': 'Narrative',\n",
        "    'Findings': 'FindingsDetail',\n",
        "    'AirCraftCategory': 'AircraftCategory',\n",
        "    'HighestInjuryLevel': 'HighestInjuryLevel',\n",
        "    'FatalInjuryCount': 'FatalInjuryCount',\n",
        "    'SeriousInjuryCount': 'SeriousInjuryCount',\n",
        "    'MinorInjuryCount': 'MinorInjuryCount',\n",
        "    'OnboardInjuryCount': 'OnboardInjuryCount',\n",
        "    'OnGroundInjuryCount': 'OnGroundInjuryCount'\n",
        "}\n",
        "\n",
        "# Renaming for ds_df (ASRS data) - based on common ASRS column names\n",
        "# Please note: these are assumed common names. If ds_df has different names,\n",
        "# this map will need adjustment based on the actual columns in ds_df.\n",
        "asrs_df_rename_map = {\n",
        "    'report_number': 'ReportID', # Assuming 'report_number' exists in ASRS data\n",
        "    'event_date': 'EventDate', # Assuming 'event_date' exists in ASRS data\n",
        "    'aircraft_type': 'AircraftModel', # ASRS often has aircraft type, we map to model for simplicity\n",
        "    'aircraft': 'AircraftMake', # If specific make is available\n",
        "    'narrative_text': 'Narrative', # Common ASRS field for incident description\n",
        "    'narrative': 'Narrative',\n",
        "    'primary_problem_area': 'EventType', # Can be mapped to event type\n",
        "    'highest_injury_level': 'HighestInjuryLevel',\n",
        "    'fatal_injury_count': 'FatalInjuryCount',\n",
        "    'serious_injury_count': 'SeriousInjuryCount',\n",
        "    'minor_injury_count': 'MinorInjuryCount',\n",
        "    'onboard_injury_count': 'OnboardInjuryCount',\n",
        "    'on_ground_injury_count': 'OnGroundInjuryCount'\n",
        "}\n",
        "\n",
        "# Apply renaming, ignore errors for columns not found in a specific dataframe\n",
        "df_renamed = df.rename(columns=nts_df_rename_map, errors='ignore')\n",
        "ds_df_renamed = ds_df.rename(columns=asrs_df_rename_map, errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "26af1085",
        "outputId": "e8fbecf8-af35-4bfa-92de-313fa3b7313a"
      },
      "source": [
        "# Concatenate the two dataframes. Non-matching columns will be filled with NaN.\n",
        "combined_df = pd.concat([df_renamed, ds_df_renamed], ignore_index=True)\n",
        "\n",
        "print(\"Combined DataFrame head:\")\n",
        "display(combined_df.head())\n",
        "print(f\"\\nShape of combined DataFrame: {combined_df.shape}\")\n",
        "print(\"\\nColumns in combined DataFrame:\")\n",
        "print(combined_df.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     ReportID EventType      Mkey             EventDate           City  \\\n",
              "0  ERA24LA084       ACC  193603.0  2023-12-31T15:13:00Z        Midland   \n",
              "1  ERA24LA079       ACC  193587.0  2023-12-30T15:04:00Z  Daytona Beach   \n",
              "2  CEN24LA081       ACC  193605.0  2023-12-29T15:27:00Z       Beaumont   \n",
              "3  WPR24LA062       ACC  193584.0  2023-12-28T10:57:00Z    Lake Havasu   \n",
              "4  WPR24LA061       ACC  193576.0  2023-12-26T13:21:00Z       Prescott   \n",
              "\n",
              "        State        Country ReportNo                  N#  \\\n",
              "0    Virginia  United States      NaN               N37GA   \n",
              "1     Florida  United States      NaN  N828AK, FA3XNWMRAN   \n",
              "2       Texas  United States      NaN               N71MS   \n",
              "3  California  United States      NaN              N312PR   \n",
              "4     Arizona  United States      NaN               N29TT   \n",
              "\n",
              "           SerialNumber  ... Events.3_Detector Events.4_When Detected  \\\n",
              "0                 004CE  ...               NaN                    NaN   \n",
              "1  1689, 163DF81001N020  ...               NaN                    NaN   \n",
              "2                 7452C  ...               NaN                    NaN   \n",
              "3                  1127  ...               NaN                    NaN   \n",
              "4                   451  ...               NaN                    NaN   \n",
              "\n",
              "  Events.5_Result Assessments_Contributing Factors / Situations  \\\n",
              "0             NaN                                           NaN   \n",
              "1             NaN                                           NaN   \n",
              "2             NaN                                           NaN   \n",
              "3             NaN                                           NaN   \n",
              "4             NaN                                           NaN   \n",
              "\n",
              "  Assessments.1_Primary Problem Report 1_Narrative  Report 1.1_Callback  \\\n",
              "0                           NaN                NaN                  NaN   \n",
              "1                           NaN                NaN                  NaN   \n",
              "2                           NaN                NaN                  NaN   \n",
              "3                           NaN                NaN                  NaN   \n",
              "4                           NaN                NaN                  NaN   \n",
              "\n",
              "   Report 2_Narrative  Report 2.1_Callback  Report 1.2_Synopsis  \n",
              "0                 NaN                  NaN                  NaN  \n",
              "1                 NaN                  NaN                  NaN  \n",
              "2                 NaN                  NaN                  NaN  \n",
              "3                 NaN                  NaN                  NaN  \n",
              "4                 NaN                  NaN                  NaN  \n",
              "\n",
              "[5 rows x 159 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8442eac1-3d4d-465b-97b2-d4b0c4983c0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReportID</th>\n",
              "      <th>EventType</th>\n",
              "      <th>Mkey</th>\n",
              "      <th>EventDate</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Country</th>\n",
              "      <th>ReportNo</th>\n",
              "      <th>N#</th>\n",
              "      <th>SerialNumber</th>\n",
              "      <th>...</th>\n",
              "      <th>Events.3_Detector</th>\n",
              "      <th>Events.4_When Detected</th>\n",
              "      <th>Events.5_Result</th>\n",
              "      <th>Assessments_Contributing Factors / Situations</th>\n",
              "      <th>Assessments.1_Primary Problem</th>\n",
              "      <th>Report 1_Narrative</th>\n",
              "      <th>Report 1.1_Callback</th>\n",
              "      <th>Report 2_Narrative</th>\n",
              "      <th>Report 2.1_Callback</th>\n",
              "      <th>Report 1.2_Synopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERA24LA084</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193603.0</td>\n",
              "      <td>2023-12-31T15:13:00Z</td>\n",
              "      <td>Midland</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N37GA</td>\n",
              "      <td>004CE</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERA24LA079</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193587.0</td>\n",
              "      <td>2023-12-30T15:04:00Z</td>\n",
              "      <td>Daytona Beach</td>\n",
              "      <td>Florida</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N828AK, FA3XNWMRAN</td>\n",
              "      <td>1689, 163DF81001N020</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CEN24LA081</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193605.0</td>\n",
              "      <td>2023-12-29T15:27:00Z</td>\n",
              "      <td>Beaumont</td>\n",
              "      <td>Texas</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N71MS</td>\n",
              "      <td>7452C</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WPR24LA062</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193584.0</td>\n",
              "      <td>2023-12-28T10:57:00Z</td>\n",
              "      <td>Lake Havasu</td>\n",
              "      <td>California</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N312PR</td>\n",
              "      <td>1127</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WPR24LA061</td>\n",
              "      <td>ACC</td>\n",
              "      <td>193576.0</td>\n",
              "      <td>2023-12-26T13:21:00Z</td>\n",
              "      <td>Prescott</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N29TT</td>\n",
              "      <td>451</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 159 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8442eac1-3d4d-465b-97b2-d4b0c4983c0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8442eac1-3d4d-465b-97b2-d4b0c4983c0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8442eac1-3d4d-465b-97b2-d4b0c4983c0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c8e1684-2a2f-4f1b-908e-9db79f3e4884\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c8e1684-2a2f-4f1b-908e-9db79f3e4884')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c8e1684-2a2f-4f1b-908e-9db79f3e4884 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of combined DataFrame: (46117, 159)\n",
            "\n",
            "Columns in combined DataFrame:\n",
            "['ReportID', 'EventType', 'Mkey', 'EventDate', 'City', 'State', 'Country', 'ReportNo', 'N#', 'SerialNumber', 'HasSafetyRec', 'Mode', 'ReportType', 'OriginalPublishedDate', 'DocketOriginalPublishedDate', 'HighestInjuryLevel', 'FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount', 'Narrative', 'FindingsDetail', 'EventID', 'Latitude', 'Longitude', 'AircraftMake', 'AircraftModel', 'AircraftCategory', 'AirportID', 'AirportName', 'AmateurBuilt', 'NumberOfEngines', 'EngineType', 'Scheduled', 'PurposeOfFlight', 'FAR', 'AirCraftDamage', 'WeatherCondition', 'Operator', 'BroadPhaseofFlight', 'ReportStatus', 'RepGenFlag', 'MostRecentReportType', 'DocketUrl', 'ReportUrl', 'rep_text', 'rep_num_jsg', 'acn_num_ACN', 'Time_Date', 'Time.1_Local Time Of Day', 'Place_Locale Reference', 'Place.1_State Reference', 'Place.2_Relative Position.Angle.Radial', 'Place.3_Relative Position.Distance.Nautical Miles', 'Place.4_Altitude.AGL.Single Value', 'Place.5_Altitude.MSL.Single Value', 'Environment_Flight Conditions', 'Environment.1_Weather Elements / Visibility', 'Environment.2_Work Environment Factor', 'Environment.3_Light', 'Environment.4_Ceiling', 'Environment.5_RVR.Single Value', 'Aircraft 1_ATC / Advisory', 'Aircraft 1.1_Aircraft Operator', 'Aircraft 1.2_Make Model Name', 'Aircraft 1.3_Aircraft Zone', 'Aircraft 1.4_Crew Size', 'Aircraft 1.5_Operating Under FAR Part', 'Aircraft 1.6_Flight Plan', 'Aircraft 1.7_Mission', 'Aircraft 1.8_Nav In Use', 'Aircraft 1.9_Flight Phase', 'Aircraft 1.10_Route In Use', 'Aircraft 1.11_Airspace', 'Aircraft 1.12_Maintenance Status.Maintenance Deferred', 'Aircraft 1.13_Maintenance Status.Records Complete', 'Aircraft 1.14_Maintenance Status.Released For Service', 'Aircraft 1.15_Maintenance Status.Required / Correct Doc On Board', 'Aircraft 1.16_Maintenance Status.Maintenance Type', 'Aircraft 1.17_Maintenance Status.Maintenance Items Involved', 'Aircraft 1.18_Cabin Lighting', 'Aircraft 1.19_Number Of Seats.Number', 'Aircraft 1.20_Passengers On Board.Number', 'Aircraft 1.21_Crew Size Flight Attendant.Number Of Crew', 'Aircraft 1.22_Airspace Authorization Provider (UAS)', 'Aircraft 1.23_Operating Under Waivers / Exemptions / Authorizations (UAS)', 'Aircraft 1.24_Waivers / Exemptions / Authorizations (UAS)', 'Aircraft 1.25_Airworthiness Certification (UAS)', 'Aircraft 1.26_Weight Category (UAS)', 'Aircraft 1.27_Configuration (UAS)', 'Aircraft 1.28_Flight Operated As (UAS)', 'Aircraft 1.29_Flight Operated with Visual Observer (UAS)', 'Aircraft 1.30_Control Mode (UAS)', 'Aircraft 1.31_Flying In / Near / Over (UAS)', 'Aircraft 1.32_Passenger Capable (UAS)', 'Aircraft 1.33_Type (UAS)', 'Aircraft 1.34_Number of UAS Being Controlled (UAS)', 'Component_Aircraft Component', 'Component.1_Manufacturer', 'Component.2_Aircraft Reference', 'Component.3_Problem', 'Aircraft 2_ATC / Advisory', 'Aircraft 2.1_Aircraft Operator', 'Aircraft 2.2_Make Model Name', 'Aircraft 2.4_Crew Size', 'Aircraft 2.5_Operating Under FAR Part', 'Aircraft 2.6_Flight Plan', 'Aircraft 2.7_Mission', 'Aircraft 2.8_Nav In Use', 'Aircraft 2.9_Flight Phase', 'Aircraft 2.10_Route In Use', 'Aircraft 2.11_Airspace', 'Aircraft 2.12_Maintenance Status.Maintenance Deferred', 'Aircraft 2.14_Maintenance Status.Released For Service', 'Aircraft 2.16_Maintenance Status.Maintenance Type', 'Aircraft 2.17_Maintenance Status.Maintenance Items Involved', 'Aircraft 2.23_Operating Under Waivers / Exemptions / Authorizations (UAS)', 'Aircraft 2.24_Waivers / Exemptions / Authorizations (UAS)', 'Aircraft 2.26_Weight Category (UAS)', 'Aircraft 2.27_Configuration (UAS)', 'Aircraft 2.28_Flight Operated As (UAS)', 'Aircraft 2.31_Flying In / Near / Over (UAS)', 'Aircraft 2.34_Number of UAS Being Controlled (UAS)', 'Person 1_Location Of Person', 'Person 1.1_Location In Aircraft', 'Person 1.2_Reporter Organization', 'Person 1.3_Function', 'Person 1.4_Qualification', 'Person 1.5_Experience', 'Person 1.6_Cabin Activity', 'Person 1.7_Human Factors', 'Person 1.8_Communication Breakdown', 'Person 1.9_UAS Communication Breakdown', 'Person 1.10_ASRS Report Number.Accession Number', 'Person 2_Location Of Person', 'Person 2.1_Location In Aircraft', 'Person 2.2_Reporter Organization', 'Person 2.3_Function', 'Person 2.4_Qualification', 'Person 2.5_Experience', 'Person 2.6_Cabin Activity', 'Person 2.7_Human Factors', 'Person 2.8_Communication Breakdown', 'Person 2.9_UAS Communication Breakdown', 'Person 2.10_ASRS Report Number.Accession Number', 'Events_Anomaly', 'Events.1_Miss Distance', 'Events.2_Were Passengers Involved In Event', 'Events.3_Detector', 'Events.4_When Detected', 'Events.5_Result', 'Assessments_Contributing Factors / Situations', 'Assessments.1_Primary Problem', 'Report 1_Narrative', 'Report 1.1_Callback', 'Report 2_Narrative', 'Report 2.1_Callback', 'Report 1.2_Synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbbbef22",
        "outputId": "db58dd4c-8115-474f-a401-7ffeb0915651"
      },
      "source": [
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 46117 entries, 0 to 46116\n",
            "Columns: 159 entries, ReportID to Report 1.2_Synopsis\n",
            "dtypes: float64(10), object(149)\n",
            "memory usage: 55.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc81f427"
      },
      "source": [
        "Please note: The column renaming for the `ds_df` (ASRS) dataset was based on common ASRS field names. If the actual column names in `ds_df` are different, the `asrs_df_rename_map` in the code above will need to be adjusted accordingly. You can inspect `ds_df.columns` if you encounter unexpected `NaN` values for supposedly common fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8132374a"
      },
      "source": [
        "print(\"Summary statistics for numerical columns:\")\n",
        "display(combined_df.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for object (non-numerical) columns:\")\n",
        "display(combined_df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a74dc49c",
        "outputId": "889ab944-ffd7-4679-a77d-a444f7e7d39d"
      },
      "source": [
        "# Convert 'EventDate' column to datetime, coercing errors\n",
        "combined_df['EventDate'] = pd.to_datetime(combined_df['EventDate'], errors='coerce')\n",
        "\n",
        "# Display the info again to confirm the change\n",
        "print(\"DataFrame info after converting 'EventDate':\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame info after converting 'EventDate':\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 46117 entries, 0 to 46116\n",
            "Columns: 159 entries, ReportID to Report 1.2_Synopsis\n",
            "dtypes: datetime64[ns, UTC](1), float64(10), object(148)\n",
            "memory usage: 55.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0a2b59a"
      },
      "source": [
        "# Calculate the percentage of missing values for each column\n",
        "missing_percentage = combined_df.isnull().sum() / len(combined_df) * 100\n",
        "\n",
        "# Display columns with missing values, sorted in descending order\n",
        "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False)\n",
        "\n",
        "print(\"Percentage of missing values per column (only showing columns with missing values):\")\n",
        "display(pd.DataFrame(missing_percentage, columns=['Missing Percentage']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2818e165"
      },
      "source": [
        "# Calculate the percentage of missing values for each column again\n",
        "missing_percentage = combined_df.isnull().sum() / len(combined_df) * 100\n",
        "\n",
        "# Display columns with missing values, sorted in descending order\n",
        "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False)\n",
        "\n",
        "print(\"Percentage of missing values per column (only showing columns with missing values):\")\n",
        "display(pd.DataFrame(missing_percentage, columns=['Missing Percentage']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ba18dc"
      },
      "source": [
        "print(\"Summary statistics for numerical columns:\")\n",
        "display(combined_df.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for object (non-numerical) columns:\")\n",
        "display(combined_df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70050bc8"
      },
      "source": [
        "# Identify columns with more than 90% missing values\n",
        "columns_to_drop_high_missing = missing_percentage[missing_percentage > 90].index.tolist()\n",
        "\n",
        "# Drop these columns from combined_df\n",
        "combined_df = combined_df.drop(columns=columns_to_drop_high_missing)\n",
        "\n",
        "print(f\"Dropped {len(columns_to_drop_high_missing)} columns with more than 90% missing values.\")\n",
        "print(\"Dropped columns:\")\n",
        "for col in columns_to_drop_high_missing:\n",
        "    print(f\"- {col}\")\n",
        "\n",
        "# Display the info again to confirm the columns are dropped\n",
        "print(\"\\nDataFrame info after dropping high missing columns:\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52a53233"
      },
      "source": [
        "print(\"Missing value percentages for NTSB data (source='NTSB'):\")\n",
        "ntsb_missing_percentage = combined_df[combined_df['source'] == 'NTSB'].isnull().sum() / len(combined_df[combined_df['source'] == 'NTSB']) * 100\n",
        "ntsb_missing_percentage = ntsb_missing_percentage[ntsb_missing_percentage > 0].sort_values(ascending=False)\n",
        "display(pd.DataFrame(ntsb_missing_percentage, columns=['Missing Percentage']))\n",
        "\n",
        "print(\"\\nMissing value percentages for ASRS data (source='ASRS'):\")\n",
        "asrs_missing_percentage = combined_df[combined_df['source'] == 'ASRS'].isnull().sum() / len(combined_df[combined_df['source'] == 'ASRS']) * 100\n",
        "asrs_missing_percentage = asrs_missing_percentage[asrs_missing_percentage > 0].sort_values(ascending=False)\n",
        "display(pd.DataFrame(asrs_missing_percentage, columns=['Missing Percentage']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "233b195f"
      },
      "source": [
        "# Calculate the percentage of missing values for each column again\n",
        "missing_percentage = combined_df.isnull().sum() / len(combined_df) * 100\n",
        "\n",
        "# Display columns with missing values, sorted in descending order\n",
        "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False)\n",
        "\n",
        "print(\"Percentage of missing values per column (only showing columns with missing values):\")\n",
        "display(pd.DataFrame(missing_percentage, columns=['Missing Percentage']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c65282a3"
      },
      "source": [
        "# Identify columns with 100% missing values\n",
        "columns_to_drop = missing_percentage[missing_percentage == 100].index.tolist()\n",
        "\n",
        "# Drop these columns from combined_df\n",
        "combined_df = combined_df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(f\"Dropped {len(columns_to_drop)} columns with 100% missing values: {columns_to_drop}\")\n",
        "\n",
        "# Display the info again to confirm the columns are dropped\n",
        "print(\"\\nDataFrame info after dropping 100% missing columns:\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60c1039d"
      },
      "source": [
        "# Task\n",
        "Clean the `combined_df` DataFrame by:\n",
        "1. Identifying and cleaning numerical outliers in 'Latitude', 'Longitude', 'FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', and 'OnGroundInjuryCount' columns.\n",
        "2. Imputing missing categorical values in object-type columns by replacing `NaN` with 'Unknown'.\n",
        "3. Creating new derived fields: `total_injuries` (sum of all injury counts) and `severity_category` (categorizing events based on `total_injuries` into 'Low', 'Medium', or 'High' severity).\n",
        "4. Re-evaluating and displaying the percentage of missing values after these cleaning steps.\n",
        "Finally, provide a summary of all data cleaning and feature engineering steps performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a711fe7c"
      },
      "source": [
        "## Identify and Clean Numerical Outliers\n",
        "\n",
        "### Subtask:\n",
        "Examine the distributions of 'Latitude', 'Longitude', and various injury count columns ('FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount'). Identify and clean any clear outliers that don't make sense by either capping them or replacing them with `NaN` if they are clearly erroneous values outside of plausible ranges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4bc77e7"
      },
      "source": [
        "**Reasoning**:\n",
        "First, replace values in the 'Latitude' column that are outside the plausible range of -90 to 90 with NaN. This is a common data cleaning step for geographical coordinates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a97011c"
      },
      "source": [
        "combined_df['Latitude'] = combined_df['Latitude'].apply(lambda x: x if -90 <= x <= 90 else pd.NA)\n",
        "print(\"Cleaned 'Latitude' column for values outside [-90, 90].\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7071b974"
      },
      "source": [
        "**Reasoning**:\n",
        "Next,clean the 'Longitude' column by replacing values outside the plausible range of -180 to 180 with NaN, similar to the 'Latitude' cleaning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a255148d"
      },
      "source": [
        "combined_df['Longitude'] = combined_df['Longitude'].apply(lambda x: x if -180 <= x <= 180 else pd.NA)\n",
        "print(\"Cleaned 'Longitude' column for values outside [-180, 180].\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163d4a49"
      },
      "source": [
        "**Reasoning**:\n",
        "Now,replace any negative values in the injury count columns ('FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount') with NaN, as injury counts cannot be negative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f97f4eae"
      },
      "source": [
        "injury_columns = ['FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount']\n",
        "\n",
        "for col in injury_columns:\n",
        "    # Ensure the column is numeric first to handle potential non-numeric entries gracefully\n",
        "    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "    # Replace negative values with NaN\n",
        "    combined_df[col] = combined_df[col].apply(lambda x: x if x >= 0 else pd.NA)\n",
        "\n",
        "print(\"Cleaned injury count columns by replacing negative values with NaN.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7348f97a"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify any extremely high, implausible values (outliers) in the injury count columns, examine their descriptive statistics, specifically the maximum values. This will help determine if any capping or replacement with NaN is necessary for values that are clearly erroneous data entries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0065ceee"
      },
      "source": [
        "print(\"Descriptive statistics for injury count columns after cleaning for negative values:\")\n",
        "display(combined_df[injury_columns].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-A1mEAzA5p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b5c1937"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `describe()` command for injury count columns did not yield numerical statistics (like `max`) because the columns were likely treated as object type due to `pd.NA` values. To properly examine numerical outliers,explicitly convert these columns to a numeric type (like `float`) before calculating descriptive statistics. This will ensure that `describe()` provides the full range of numerical summaries including the maximum values, which are crucial for identifying implausible outliers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bee7da5"
      },
      "source": [
        "## Identify and Flag Numerical Outliers\n",
        "\n",
        "### Subtask:\n",
        "Create a new boolean column `is_extreme_injury` to flag rows where 'MinorInjuryCount' or 'OnboardInjuryCount' exceed a threshold of 50, without altering the original injury count values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7b02b91"
      },
      "source": [
        "injury_columns = ['FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount']\n",
        "\n",
        "for col in injury_columns:\n",
        "    # Convert to float, replacing any non-numeric values (including pd.NA) with NaN\n",
        "    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "print(\"Descriptive statistics for injury count columns after ensuring numeric type:\")\n",
        "display(combined_df[injury_columns].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c07ba3f"
      },
      "source": [
        "extreme_injury_threshold = 50\n",
        "\n",
        "combined_df['is_extreme_injury'] = (\n",
        "    (combined_df['MinorInjuryCount'] > extreme_injury_threshold) |\n",
        "    (combined_df['OnboardInjuryCount'] > extreme_injury_threshold)\n",
        ")\n",
        "\n",
        "print(f\"New column 'is_extreme_injury' created. Flagging cases where 'MinorInjuryCount' or 'OnboardInjuryCount' exceed {extreme_injury_threshold}.\")\n",
        "\n",
        "print(\"First 5 rows with 'MinorInjuryCount', 'OnboardInjuryCount', and 'is_extreme_injury':\")\n",
        "display(combined_df[['MinorInjuryCount', 'OnboardInjuryCount', 'is_extreme_injury']].head())\n",
        "\n",
        "extreme_injury_count = combined_df['is_extreme_injury'].sum()\n",
        "print(f\"Total identified extreme injury cases: {extreme_injury_count}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c2deaa3"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that numerical outliers have been addressed for Latitude, Longitude, and injury counts, the next step is to impute missing categorical values in object-type columns as per the overall task requirements. I will iterate through all object-type columns and replace any NaN values with the string 'Unknown'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc60c339"
      },
      "source": [
        "print(\"Imputing missing categorical values with 'Unknown'...\")\n",
        "\n",
        "# Get a list of all object (string) columns\n",
        "object_columns = combined_df.select_dtypes(include='object').columns\n",
        "\n",
        "# Impute missing values in these columns with 'Unknown'\n",
        "for col in object_columns:\n",
        "    combined_df[col] = combined_df[col].fillna('Unknown')\n",
        "\n",
        "print(\"Missing categorical values imputed.\")\n",
        "\n",
        "# Verify imputation by checking missing values in object columns\n",
        "print(\"\\nMissing values in object columns after imputation:\")\n",
        "missing_in_object_columns = combined_df[object_columns].isnull().sum()\n",
        "missing_in_object_columns = missing_in_object_columns[missing_in_object_columns > 0]\n",
        "display(missing_in_object_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80340e48"
      },
      "source": [
        " next step: to create the derived field `total_injuries` by summing up all the individual injury count columns. This will provide a consolidated measure of injury severity for each event.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1291249"
      },
      "source": [
        "print(\"Creating 'total_injuries' column...\")\n",
        "\n",
        "injury_columns = ['FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount']\n",
        "\n",
        "# Ensure all injury columns are numeric before summing\n",
        "for col in injury_columns:\n",
        "    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# Sum the injury columns, treating NaN as 0 for the sum\n",
        "combined_df['total_injuries'] = combined_df[injury_columns].fillna(0).sum(axis=1)\n",
        "\n",
        "print(\"'total_injuries' column created.\")\n",
        "print(\"First 5 rows with 'total_injuries' column:\")\n",
        "display(combined_df[['FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount', 'total_injuries']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef328a66"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully created the 'total_injuries' column but generated a `PerformanceWarning` due to DataFrame fragmentation. To address this and prevent future warnings, I will explicitly de-fragment `combined_df` by making a copy of it. Then, I will proceed to create the `severity_category` column based on the `total_injuries`, as per the overall task instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc765a4f"
      },
      "source": [
        "print(\"Creating 'total_injuries' and 'severity_category' columns...\")\n",
        "\n",
        "injury_columns = ['FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', 'OnGroundInjuryCount']\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Ensure all injury columns are numeric before summing\n",
        "for col in injury_columns:\n",
        "    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# Sum the injury columns, treating NaN as 0 for the sum\n",
        "combined_df['total_injuries'] = combined_df[injury_columns].fillna(0).sum(axis=1)\n",
        "\n",
        "# Define bins and labels for severity categorization\n",
        "bins = [-1, 0, 5, combined_df['total_injuries'].max() + 1] # -1 to include 0 injuries\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Create 'severity_category' column\n",
        "combined_df['severity_category'] = pd.cut(\n",
        "    combined_df['total_injuries'],\n",
        "    bins=bins,\n",
        "    labels=labels,\n",
        "    right=True # bins are (min, max]\n",
        ")\n",
        "\n",
        "print(\"'total_injuries' and 'severity_category' columns created.\")\n",
        "print(\"First 5 rows with new columns:\")\n",
        "display(combined_df[['total_injuries', 'severity_category']].head())\n",
        "print(\"Value counts for 'severity_category':\")\n",
        "display(combined_df['severity_category'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fccdda2f"
      },
      "source": [
        "**Reasoning**:\n",
        " re-evaluate and display the percentage of missing values for all columns in the `combined_df` to understand the current data completeness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fd99a67"
      },
      "source": [
        "print(\"Re-evaluating percentage of missing values for all columns:\")\n",
        "\n",
        "# Calculate the percentage of missing values for each column\n",
        "missing_percentage_after_cleaning = combined_df.isnull().sum() / len(combined_df) * 100\n",
        "\n",
        "# Display columns with missing values, sorted in descending order\n",
        "missing_percentage_after_cleaning = missing_percentage_after_cleaning[missing_percentage_after_cleaning > 0].sort_values(ascending=False)\n",
        "\n",
        "# Display the results\n",
        "if not missing_percentage_after_cleaning.empty:\n",
        "    display(pd.DataFrame(missing_percentage_after_cleaning, columns=['Missing Percentage']))\n",
        "else:\n",
        "    print(\"No missing values found after cleaning and feature engineering.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a466464c"
      },
      "source": [
        "## Summary of Data Cleaning and Feature Engineering Steps Performed:\n",
        "\n",
        "1.  **Numerical Outlier Cleaning (Latitude & Longitude)**:\n",
        "    *   'Latitude' values outside the range of -90 to 90 were replaced with `pd.NA`.\n",
        "    *   'Longitude' values outside the range of -180 to 180 were replaced with `pd.NA`.\n",
        "\n",
        "2.  **Numerical Outlier Cleaning (Injury Counts)**:\n",
        "    *   For 'FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', and 'OnGroundInjuryCount', any negative values were replaced with `pd.NA` as injury counts cannot be negative.\n",
        "\n",
        "3.  **Outlier Flagging (`is_extreme_injury`)**:\n",
        "    *   A new boolean column `is_extreme_injury` was created. This column flags rows where either 'MinorInjuryCount' or 'OnboardInjuryCount' exceeds a threshold of 50, allowing for separate analysis of these extreme cases without altering the original injury count values.\n",
        "\n",
        "4.  **Categorical Imputation**:\n",
        "    *   All missing values (`NaN`) in columns with `object` (string) data types were imputed by replacing them with the string 'Unknown'.\n",
        "\n",
        "5.  **Feature Engineering (`total_injuries`)**:\n",
        "    *   A new column named `total_injuries` was created, which is the sum of 'FatalInjuryCount', 'SeriousInjuryCount', 'MinorInjuryCount', 'OnboardInjuryCount', and 'OnGroundInjuryCount'. Missing values in these injury columns were treated as 0 for the summation.\n",
        "\n",
        "6.  **Feature Engineering (`severity_category`)**:\n",
        "    *   A new categorical column named `severity_category` was created based on the `total_injuries` column. Events were categorized into 'Low' (0 injuries), 'Medium' (1 to 5 injuries), or 'High' (more than 5 injuries).\n",
        "\n",
        "7.  **DataFrame De-fragmentation**:\n",
        "    *   The `combined_df` DataFrame was explicitly de-fragmented using `.copy()` to improve performance and prevent `PerformanceWarning` during column additions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69c9a961"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A new boolean column, `is_extreme_injury`, was successfully created to flag rows where `MinorInjuryCount` or `OnboardInjuryCount` exceeded a threshold of 50.\n",
        "*   Only 1 row in the dataset was identified as having extreme injury counts (either `MinorInjuryCount` or `OnboardInjuryCount` greater than 50).\n",
        "*   Missing values in all object (categorical) columns were imputed with the string 'Unknown'.\n",
        "*   A new column `total_injuries` was calculated by summing all types of injury counts, treating any missing injury counts as 0.\n",
        "*   A `severity_category` column was created based on `total_injuries`, categorizing events into 'Low' (0 injuries), 'Medium' (1 to 5 injuries), and 'High' (more than 5 injuries).\n",
        "*   After these cleaning and feature engineering steps, no columns were found to have missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9d2f3c"
      },
      "source": [
        "print(\"Summary statistics for numerical columns:\")\n",
        "display(combined_df.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for object (non-numerical) columns:\")\n",
        "display(combined_df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38fa8135"
      },
      "source": [
        "print(\"Details of the extreme injury case (is_extreme_injury = True):\")\n",
        "extreme_case = combined_df[combined_df['is_extreme_injury'] == True]\n",
        "\n",
        "display(extreme_case[['MinorInjuryCount', 'OnboardInjuryCount', 'total_injuries', 'Narrative', 'source']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aa415fa"
      },
      "source": [
        "print(\"Summary statistics for numerical columns:\")\n",
        "display(combined_df.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for object (non-numerical) columns:\")\n",
        "display(combined_df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e619163"
      },
      "source": [
        "print(combined_df.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e99d2fe"
      },
      "source": [
        "for col, dtype in combined_df.dtypes.items():\n",
        "    print(f\"{col}: {dtype}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1760802a"
      },
      "source": [
        "print(\"Replacing 'Unknown', 'UNK', and empty strings with NaN in object columns...\")\n",
        "\n",
        "# Get a list of all object (string) columns in the current combined_df\n",
        "object_columns = combined_df.select_dtypes(include='object').columns\n",
        "\n",
        "# Define values to replace\n",
        "values_to_replace = ['Unknown', 'UNK', '']\n",
        "\n",
        "for col in object_columns:\n",
        "    # Use .replace() with a list of values to replace with pd.NA\n",
        "    # The regex=False is important when replacing exact strings to avoid regex interpretation\n",
        "    combined_df[col] = combined_df[col].replace(values_to_replace, pd.NA)\n",
        "\n",
        "print(\"Replacement complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac36f21c"
      },
      "source": [
        "print(\"Summary statistics for numerical columns:\")\n",
        "display(combined_df.describe())\n",
        "\n",
        "print(\"\\nSummary statistics for object (non-numerical) columns:\")\n",
        "display(combined_df.describe(include='object'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing columns that are not neccesarry for our analysis"
      ],
      "metadata": {
        "id": "cR1PnkG4CKv0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8baa288c"
      },
      "source": [
        "columns_to_keep = [\n",
        "    'ReportID',\n",
        "    'EventType',\n",
        "    'City',\n",
        "    'State',\n",
        "    'Country',\n",
        "    'Mode',\n",
        "    'ReportType',\n",
        "    'EventDate',\n",
        "    'N#',\n",
        "    'SerialNumber',\n",
        "    'FatalInjuryCount',\n",
        "    'SeriousInjuryCount',\n",
        "    'MinorInjuryCount',\n",
        "    'OnboardInjuryCount',\n",
        "    'OnGroundInjuryCount',\n",
        "    'total_injuries',\n",
        "    'Report 1_Narrative',\n",
        "    'Report 1.2_Synopsis',\n",
        "    'Events.3_Detector',\n",
        "    'Events.4_When Detected',\n",
        "    'Events.5_Result',\n",
        "    'Assessments_Contributing Factors / Situations',\n",
        "    'Assessments.1_Primary Problem'\n",
        "]\n",
        "\n",
        "# Filter the DataFrame to keep only the specified columns\n",
        "combined_df = combined_df[columns_to_keep]\n",
        "\n",
        "print(f\"DataFrame now contains {combined_df.shape[1]} columns.\")\n",
        "print(\"First 5 rows of the filtered DataFrame:\")\n",
        "display(combined_df.head())\n",
        "print(\"\\nUpdated column list and their data types:\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e05c053f"
      },
      "source": [
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171a230a"
      },
      "source": [
        " identify all columns with 'object' dtype in `combined_df` that contain the string 'Unknown'. This will involve selecting object-type columns and then checking each column's unique values for the presence of 'Unknown'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d7b0690"
      },
      "source": [
        "print(\"Identifying object columns containing 'Unknown' values...\")\n",
        "\n",
        "# Get a list of all object (string) columns\n",
        "object_columns = combined_df.select_dtypes(include='object').columns\n",
        "\n",
        "# List to store columns that contain 'Unknown'\n",
        "columns_with_unknown = []\n",
        "\n",
        "for col in object_columns:\n",
        "    if 'Unknown' in combined_df[col].unique():\n",
        "        columns_with_unknown.append(col)\n",
        "\n",
        "print(f\"Found {len(columns_with_unknown)} object columns containing 'Unknown' values.\")\n",
        "\n",
        "if columns_with_unknown:\n",
        "    print(\"\\nObject columns containing 'Unknown' values:\")\n",
        "    for col in columns_with_unknown:\n",
        "        print(f\"- {col}\")\n",
        "else:\n",
        "    print(\"No object columns found containing 'Unknown' values.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf5012dd"
      },
      "source": [
        "**Reasoning**:\n",
        " calculate the count of 'Unknown' entries for each identified column, sort them in descending order, and then display the top 5 columns along with their unique value counts. This will highlight which columns have the most 'Unknown' values and give a sense of their distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac510559"
      },
      "source": [
        "print(\"Displaying unique value counts for top 5 columns with the most 'Unknown' entries...\")\n",
        "\n",
        "# Calculate the count of 'Unknown' in each column\n",
        "unknown_counts = {col: (combined_df[col] == 'Unknown').sum() for col in columns_with_unknown}\n",
        "\n",
        "# Sort columns by the number of 'Unknown' values in descending order\n",
        "sorted_columns_by_unknown = sorted(unknown_counts.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Display unique values and their counts for the top 5 columns with the most 'Unknown' entries\n",
        "num_columns_to_display = 5\n",
        "for col_name, count in sorted_columns_by_unknown[:num_columns_to_display]:\n",
        "    print(f\"\\nColumn: '{col_name}' (Count of 'Unknown': {count})\")\n",
        "    display(combined_df[col_name].value_counts(dropna=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0412717f"
      },
      "source": [
        "# Task\n",
        "Create a `SubsystemAffected` column as a categorical variable (Engine, Electrical, LandingGear, Avionics, Cabin, Hydraulics, or Other/Unknown) in the `combined_df` DataFrame. The values for this column should be derived by searching for keywords within the 'Report 1_Narrative' and 'Report 1.2_Synopsis' columns. If no specific subsystem is identified, default the value to 'Other/Unknown'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a07118b2"
      },
      "source": [
        "## Add SubsystemAffected Column\n",
        "\n",
        "### Subtask:\n",
        "Create the SubsystemAffected column as a categorical variable (Engine, Electrical, LandingGear, Avionics, Cabin, Hydraulics, or Other/Unknown) in the combined_df DataFrame. The values for this column should be derived by searching for keywords within the 'Report 1_Narrative' and 'Report 1.2_Synopsis' columns. If no specific subsystem is identified, default the value to 'Other/Unknown'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a02b1135"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to initialize the new `SubsystemAffected` column in `combined_df` with the default value 'Other/Unknown' for all rows, as per the first instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e169f49"
      },
      "source": [
        "print(\"Initializing 'SubsystemAffected' column with 'Other/Unknown'...\")\n",
        "combined_df['SubsystemAffected'] = 'Other/Unknown'\n",
        "print(\"Initialization complete.\")\n",
        "print(\"First 5 rows with 'SubsystemAffected' column:\")\n",
        "display(combined_df[['Report 1_Narrative', 'Report 1.2_Synopsis', 'SubsystemAffected']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f403acc"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the instructions, I need to define a dictionary of subsystems and their corresponding keywords to be searched in the narrative columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0010aec4"
      },
      "source": [
        "print(\"Defining subsystem keywords...\")\n",
        "\n",
        "subsystem_keywords = {\n",
        "    'Engine': ['engine', 'propeller', 'turbine', 'jet', 'apu', 'motor', 'thrust', 'compressor', 'fan', 'combustor', 'exhaust', 'fuel pump', 'oil pressure', 'rpm', 'cylinder'],\n",
        "    'Electrical': ['electrical', 'battery', 'generator', 'alternator', 'avionics power', 'circuit breaker', 'bus bar', 'wiring', 'voltage', 'current', 'relay', 'power supply'],\n",
        "    'LandingGear': ['landing gear', 'wheel', 'tire', 'brake', 'retraction', 'extension', 'strut', 'actuator', 'gear indication', 'nose wheel', 'main gear'],\n",
        "    'Avionics': ['avionics', 'navigation', 'radio', 'gps', 'autopilot', 'fms', 'instrument', 'display', 'radar', 'transponder', 'communication', 'adi', 'hsi', 'altimeter'],\n",
        "    'Cabin': ['cabin', 'passenger', 'door', 'emergency exit', 'lavatory', 'galley', 'seat', 'oxygen mask', 'pressurization', 'environmental control', 'cargo hold'],\n",
        "    'Hydraulics': ['hydraulic', 'fluid', 'pump', 'actuator', 'reservoir', 'pressure', 'line', 'leak', 'accumulator', 'valve', 'power control']\n",
        "}\n",
        "\n",
        "print(\"Subsystem keywords defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "952c7746"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will define a function that iterates through the defined `subsystem_keywords` and checks if any of the keywords for a given subsystem are present in the 'Report 1_Narrative' or 'Report 1.2_Synopsis' columns of a DataFrame row. The function will return the first matching subsystem or 'Other/Unknown' if no match is found, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ca3db2b"
      },
      "source": [
        "print(\"Defining function to identify SubsystemAffected...\")\n",
        "\n",
        "def identify_subsystem(row):\n",
        "    narrative = str(row['Report 1_Narrative']).lower()\n",
        "    synopsis = str(row['Report 1.2_Synopsis']).lower()\n",
        "\n",
        "    for subsystem, keywords in subsystem_keywords.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in narrative or keyword in synopsis:\n",
        "                return subsystem\n",
        "    return 'Other/Unknown'\n",
        "\n",
        "print(\"Function 'identify_subsystem' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65e0c29b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to apply the `identify_subsystem` function to each row of the `combined_df` DataFrame to populate the `SubsystemAffected` column, as specified in the subtask instructions. After applying, I will display the value counts of the new column to verify the distribution of categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25d52b7b"
      },
      "source": [
        "print(\"Applying 'identify_subsystem' function to populate 'SubsystemAffected' column...\")\n",
        "\n",
        "# Apply the function to each row to populate the 'SubsystemAffected' column\n",
        "combined_df['SubsystemAffected'] = combined_df.apply(identify_subsystem, axis=1)\n",
        "\n",
        "print(\"'SubsystemAffected' column populated.\")\n",
        "\n",
        "print(\"\\nValue counts for 'SubsystemAffected' column:\")\n",
        "display(combined_df['SubsystemAffected'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62993dd5"
      },
      "source": [
        "## Add PhaseOfFlight Column\n",
        "\n",
        "### Subtask:\n",
        "Create the PhaseOfFlight column as a categorical variable (Taxi, Takeoff, Climb, Cruise, Descent, Landing, or Other/Unknown). Values will be assigned by searching for relevant keywords in the narrative columns. If no specific phase is identified, it will default to 'Other/Unknown'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22971519"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `phase_of_flight_keywords` dictionary as specified in the instructions (step 2) before defining and applying the `identify_phase_of_flight` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cdf6a5f"
      },
      "source": [
        "print(\"Defining phase of flight keywords...\")\n",
        "\n",
        "phase_of_flight_keywords = {\n",
        "    'Taxi': ['taxi', 'pushback', 'gate', 'ramp', 'apron', 'tow'],\n",
        "    'Takeoff': ['takeoff', 'rotation', 'lift-off', 'departure', 'runway', 'initial climb'],\n",
        "    'Climb': ['climb', 'ascending', 'enroute climb', 'climbing'],\n",
        "    'Cruise': ['cruise', 'en route', 'altitude', 'level flight', 'flight level'],\n",
        "    'Descent': ['descent', 'descending', 'approach preparation', 'top of descent'],\n",
        "    'Landing': ['landing', 'touchdown', 'final approach', 'flare', 'rollout', 'arrival', 'touch and go'],\n",
        "    'Go-around': ['go-around', 'rejected landing', 'missed approach'],\n",
        "    'Holding': ['holding', 'pattern', 'stack']\n",
        "}\n",
        "\n",
        "print(\"Phase of flight keywords defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e74765f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `phase_of_flight_keywords` are defined, I need to define the `identify_phase_of_flight` function that will use these keywords to determine the phase of flight from the narrative columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e05189e"
      },
      "source": [
        "# Task\n",
        "**Reasoning**:\n",
        "Now that the `phase_of_flight_keywords` are defined, I will define the `identify_phase_of_flight` function. This function will iterate through these keywords and check for their presence in the 'Report 1_Narrative' or 'Report 1.2_Synopsis' columns for each row. If a keyword is found, the corresponding phase of flight will be assigned; otherwise, it will default to 'Other/Unknown'. This function will then be applied to the `combined_df` to create the `PhaseOfFlight` column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27bb6bb9"
      },
      "source": [
        "## Define identify_phase_of_flight Function\n",
        "\n",
        "### Subtask:\n",
        "Define a function to identify the phase of flight based on keywords in narrative columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1afafc15"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `identify_phase_of_flight` function as per the subtask instructions, which will take a DataFrame row and use the previously defined `phase_of_flight_keywords` to determine the phase of flight.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49b37f7e"
      },
      "source": [
        "print(\"Defining function to identify PhaseOfFlight...\")\n",
        "\n",
        "def identify_phase_of_flight(row):\n",
        "    narrative = str(row['Report 1_Narrative']).lower()\n",
        "    synopsis = str(row['Report 1.2_Synopsis']).lower()\n",
        "\n",
        "    for phase, keywords in phase_of_flight_keywords.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in narrative or keyword in synopsis:\n",
        "                return phase\n",
        "    return 'Other/Unknown'\n",
        "\n",
        "print(\"Function 'identify_phase_of_flight' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18db9c4f"
      },
      "source": [
        "**Reasoning**:\n",
        "The `identify_phase_of_flight` function has been defined, and now I need to apply this function to each row of the `combined_df` DataFrame to create the new `PhaseOfFlight` column. After populating the column, I will display its value counts to confirm the new categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38a56af7"
      },
      "source": [
        "print(\"Applying 'identify_phase_of_flight' function to populate 'PhaseOfFlight' column...\")\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before adding a new column\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to populate the 'PhaseOfFlight' column\n",
        "combined_df['PhaseOfFlight'] = combined_df.apply(identify_phase_of_flight, axis=1)\n",
        "\n",
        "print(\"'PhaseOfFlight' column populated.\")\n",
        "\n",
        "print(\"\\nValue counts for 'PhaseOfFlight' column:\")\n",
        "display(combined_df['PhaseOfFlight'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b201846a"
      },
      "source": [
        "## Add SensorWarning Column\n",
        "\n",
        "### Subtask:\n",
        "Create the SensorWarning column (0 or 1). A value of 1 will be assigned if keywords indicating a sensor warning or alert are found in the narrative columns, or if there are specific entries in 'Events.3_Detector' or 'Events.4_When Detected' that imply a warning. Otherwise, it will be 0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e977f25"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to initialize the new `SensorWarning` column in `combined_df` with a default value of 0, as per the first instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b245c43"
      },
      "source": [
        "print(\"Initializing 'SensorWarning' column with 0...\")\n",
        "combined_df['SensorWarning'] = 0\n",
        "print(\"Initialization complete.\")\n",
        "print(\"First 5 rows with 'SensorWarning' column:\")\n",
        "display(combined_df[['Report 1_Narrative', 'Report 1.2_Synopsis', 'SensorWarning']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9e50aa"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the subtask instructions, I need to define a list of keywords related to sensor warnings and alerts to be used for searching within the narrative columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852b18a4"
      },
      "source": [
        "print(\"Defining sensor warning keywords...\")\n",
        "\n",
        "sensor_warning_keywords = [\n",
        "    'warning', 'alert', 'caution', 'alarm', 'light', 'indicator',\n",
        "    'failure', 'malfunction', 'anomaly', 'detector', 'smoke', 'fire',\n",
        "    'overheat', 'stall', 'low pressure', 'high temp', 'hot start', 'chip detector',\n",
        "    'gear warning', 'takeoff warning', 'master warning', 'master caution', 'EICAS', 'ECAM', 'ACARS'\n",
        "]\n",
        "\n",
        "print(\"Sensor warning keywords defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220aaccf"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3 of the subtask, I need to define another list of keywords/values to check in the 'Events.3_Detector' and 'Events.4_When Detected' columns that might imply a sensor warning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac66d108"
      },
      "source": [
        "print(\"Defining detector/when detected keywords...\")\n",
        "\n",
        "detector_when_detected_keywords = [\n",
        "    'sensor', 'detector', 'ecam', 'eicas', 'acars', 'warning system',\n",
        "    'master warning', 'master caution', 'alert system', 'indication',\n",
        "    'light came on', 'aural warning', 'visual alert'\n",
        "]\n",
        "\n",
        "print(\"Detector/when detected keywords defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ee06560"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that all keyword lists are defined, I need to create a function that applies the logic described in the subtask instructions (step 4). This function will check the narrative columns ('Report 1_Narrative', 'Report 1.2_Synopsis') and the detector columns ('Events.3_Detector', 'Events.4_When Detected') for the defined keywords, and return 1 if a sensor warning is implied, otherwise 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3773799"
      },
      "source": [
        "print(\"Defining function to identify sensor warnings...\")\n",
        "\n",
        "def identify_sensor_warning(row):\n",
        "    narrative = str(row['Report 1_Narrative']).lower()\n",
        "    synopsis = str(row['Report 1.2_Synopsis']).lower()\n",
        "    detector = str(row['Events.3_Detector']).lower()\n",
        "    when_detected = str(row['Events.4_When Detected']).lower()\n",
        "\n",
        "    # Check narrative and synopsis for sensor warning keywords\n",
        "    for keyword in sensor_warning_keywords:\n",
        "        if keyword in narrative or keyword in synopsis:\n",
        "            return 1\n",
        "\n",
        "    # Check detector and when_detected columns for relevant keywords\n",
        "    for keyword in detector_when_detected_keywords:\n",
        "        if keyword in detector or keyword in when_detected:\n",
        "            return 1\n",
        "\n",
        "    return 0\n",
        "\n",
        "print(\"Function 'identify_sensor_warning' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a6aba06"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `identify_sensor_warning` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to populate the `SensorWarning` column. After populating, I will display the value counts for the new column to verify the distribution of 0s and 1s, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bb3cbbe"
      },
      "source": [
        "print(\"Applying 'identify_sensor_warning' function to populate 'SensorWarning' column...\")\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before adding a new column\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to populate the 'SensorWarning' column\n",
        "combined_df['SensorWarning'] = combined_df.apply(identify_sensor_warning, axis=1)\n",
        "\n",
        "print(\"'SensorWarning' column populated.\")\n",
        "\n",
        "print(\"\\nValue counts for 'SensorWarning' column:\")\n",
        "display(combined_df['SensorWarning'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000d4be6"
      },
      "source": [
        "## Add HydraulicPressureDrop Column\n",
        "\n",
        "### Subtask:\n",
        "Create the `HydraulicPressureDrop` column with values between 0 and 30, synthetically generated based on `SubsystemAffected` and modulated by `total_injuries`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdc08269"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to import the `numpy` library as `np` to use its random number generation and clipping functionalities, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e2db8b1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Imported numpy as np.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a514fc1"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the instructions, I need to de-fragment the `combined_df` DataFrame by creating a copy to prevent `PerformanceWarning` when adding new columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "845c1f9e"
      },
      "source": [
        "print(\"De-fragmenting combined_df...\")\n",
        "combined_df = combined_df.copy()\n",
        "print(\"combined_df de-fragmented.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5973c2b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `generate_hydraulic_pressure_drop` function as specified in the instructions (step 3), which will take a DataFrame row as input and calculate a synthetic hydraulic pressure drop value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76f6fa8"
      },
      "source": [
        "print(\"Defining function to generate HydraulicPressureDrop...\")\n",
        "\n",
        "def generate_hydraulic_pressure_drop(row):\n",
        "    # Ensure total_injuries is numeric, handle potential NaNs\n",
        "    total_injuries = pd.to_numeric(row['total_injuries'], errors='coerce')\n",
        "    if pd.isna(total_injuries):\n",
        "        total_injuries = 0 # Default to 0 if total_injuries is NaN\n",
        "\n",
        "    if row['SubsystemAffected'] == 'Hydraulics':\n",
        "        base_value = np.random.uniform(low=15, high=28)\n",
        "    else:\n",
        "        base_value = np.random.uniform(low=0, high=12)\n",
        "\n",
        "    # Calculate modulation factor based on total_injuries\n",
        "    # Add 1 to max() to prevent division by zero and ensure positive factor\n",
        "    max_total_injuries = combined_df['total_injuries'].max()\n",
        "    if max_total_injuries == 0:\n",
        "        modulation_factor = 1 # If no injuries, no modulation\n",
        "    else:\n",
        "        modulation_factor = 1 + (total_injuries / (max_total_injuries + 1))\n",
        "\n",
        "    # Apply modulation and clip the value to the desired range [0, 30]\n",
        "    calculated_value = base_value * modulation_factor\n",
        "    return np.clip(calculated_value, 0, 30)\n",
        "\n",
        "print(\"Function 'generate_hydraulic_pressure_drop' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e5a2284"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `generate_hydraulic_pressure_drop` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to create the new `HydraulicPressureDrop` column, as per the subtask instructions (step 4). After applying, I will display the first few rows of the DataFrame showing the new column (step 5) and its descriptive statistics (step 6).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ad075c6"
      },
      "source": [
        "print(\"Applying 'generate_hydraulic_pressure_drop' function to populate 'HydraulicPressureDrop' column...\")\n",
        "\n",
        "# Apply the function to each row\n",
        "combined_df['HydraulicPressureDrop'] = combined_df.apply(generate_hydraulic_pressure_drop, axis=1)\n",
        "\n",
        "print(\"'HydraulicPressureDrop' column populated.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with 'HydraulicPressureDrop' column:\")\n",
        "display(combined_df[['SubsystemAffected', 'total_injuries', 'HydraulicPressureDrop']].head())\n",
        "\n",
        "print(\"\\nDescriptive statistics for 'HydraulicPressureDrop' column:\")\n",
        "display(combined_df['HydraulicPressureDrop'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c10285ff"
      },
      "source": [
        "## Add EngineTempDeviation Column\n",
        "\n",
        "### Subtask:\n",
        "Create the `EngineTempDeviation` column with values between 0 and 30, synthetically generated based on `SubsystemAffected` and modulated by `total_injuries`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3ec414"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `generate_engine_temp_deviation` function as specified in the instructions (step 1), which will take a DataFrame row as input and calculate a synthetic engine temperature deviation value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a5c2456"
      },
      "source": [
        "print(\"Defining function to generate EngineTempDeviation...\")\n",
        "\n",
        "def generate_engine_temp_deviation(row):\n",
        "    # Ensure total_injuries is numeric, handle potential NaNs (step 2)\n",
        "    total_injuries = pd.to_numeric(row['total_injuries'], errors='coerce')\n",
        "    if pd.isna(total_injuries):\n",
        "        total_injuries = 0 # Default to 0 if total_injuries is NaN\n",
        "\n",
        "    # Generate base value based on SubsystemAffected (step 3)\n",
        "    if row['SubsystemAffected'] == 'Engine':\n",
        "        base_value = np.random.uniform(low=15, high=28)\n",
        "    else:\n",
        "        base_value = np.random.uniform(low=0, high=12)\n",
        "\n",
        "    # Calculate modulation factor based on total_injuries (step 4)\n",
        "    # Add 1 to max() to prevent division by zero and ensure positive factor\n",
        "    max_total_injuries = combined_df['total_injuries'].max()\n",
        "    if max_total_injuries == 0:\n",
        "        modulation_factor = 1 # If no injuries, no modulation\n",
        "    else:\n",
        "        modulation_factor = 1 + (total_injuries / (max_total_injuries + 1))\n",
        "\n",
        "    # Apply modulation and clip the value to the desired range [0, 30] (steps 5 and 6)\n",
        "    calculated_value = base_value * modulation_factor\n",
        "    return np.clip(calculated_value, 0, 30) # Return clipped value (step 7)\n",
        "\n",
        "print(\"Function 'generate_engine_temp_deviation' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c535e5b9"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `generate_engine_temp_deviation` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to create the new `EngineTempDeviation` column, as per the subtask instructions (step 8). After applying, I will display the first few rows of the DataFrame showing the new column (step 9) and its descriptive statistics (step 10).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e1f1011"
      },
      "source": [
        "print(\"Applying 'generate_engine_temp_deviation' function to populate 'EngineTempDeviation' column...\")\n",
        "\n",
        "# Apply the function to each row\n",
        "combined_df['EngineTempDeviation'] = combined_df.apply(generate_engine_temp_deviation, axis=1)\n",
        "\n",
        "print(\"'EngineTempDeviation' column populated.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with 'EngineTempDeviation' column:\")\n",
        "display(combined_df[['SubsystemAffected', 'total_injuries', 'EngineTempDeviation']].head())\n",
        "\n",
        "print(\"\\nDescriptive statistics for 'EngineTempDeviation' column:\")\n",
        "display(combined_df['EngineTempDeviation'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e50abfdb"
      },
      "source": [
        "## Add ElectricalLoadSpike Column\n",
        "\n",
        "### Subtask:\n",
        "Create the `ElectricalLoadSpike` column with values between 0 and 20, synthetically generated based on `SubsystemAffected` and modulated by `total_injuries`. If `SubsystemAffected` is 'Electrical', assign a higher, randomized value within the range; otherwise, assign a lower, randomized value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90023f4b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `generate_electrical_load_spike` function as specified in the instructions (step 1), which will take a DataFrame row as input and calculate a synthetic electrical load spike value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc5feac6"
      },
      "source": [
        "print(\"Defining function to generate ElectricalLoadSpike...\")\n",
        "\n",
        "def generate_electrical_load_spike(row):\n",
        "    # Ensure total_injuries is numeric, handle potential NaNs (step 2)\n",
        "    total_injuries = pd.to_numeric(row['total_injuries'], errors='coerce')\n",
        "    if pd.isna(total_injuries):\n",
        "        total_injuries = 0 # Default to 0 if total_injuries is NaN\n",
        "\n",
        "    # Generate base value based on SubsystemAffected (step 3)\n",
        "    if row['SubsystemAffected'] == 'Electrical':\n",
        "        base_value = np.random.uniform(low=10, high=18)\n",
        "    else:\n",
        "        base_value = np.random.uniform(low=0, high=8)\n",
        "\n",
        "    # Calculate modulation factor based on total_injuries (step 4)\n",
        "    # Add 1 to max() to prevent division by zero and ensure positive factor\n",
        "    max_total_injuries = combined_df['total_injuries'].max()\n",
        "    if max_total_injuries == 0:\n",
        "        modulation_factor = 1 # If no injuries, no modulation\n",
        "    else:\n",
        "        modulation_factor = 1 + (total_injuries / (max_total_injuries + 1))\n",
        "\n",
        "    # Apply modulation and clip the value to the desired range [0, 20] (steps 5 and 6)\n",
        "    calculated_value = base_value * modulation_factor\n",
        "    return np.clip(calculated_value, 0, 20) # Return clipped value (step 7)\n",
        "\n",
        "print(\"Function 'generate_electrical_load_spike' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2dd2c25"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `generate_electrical_load_spike` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to create the new `ElectricalLoadSpike` column, as per the subtask instructions (step 8). After applying, I will display the first few rows of the DataFrame showing the new column (step 9) and its descriptive statistics (step 10).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a9b3673"
      },
      "source": [
        "print(\"Applying 'generate_electrical_load_spike' function to populate 'ElectricalLoadSpike' column...\")\n",
        "\n",
        "# Apply the function to each row\n",
        "combined_df['ElectricalLoadSpike'] = combined_df.apply(generate_electrical_load_spike, axis=1)\n",
        "\n",
        "print(\"'ElectricalLoadSpike' column populated.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with 'ElectricalLoadSpike' column:\")\n",
        "display(combined_df[['SubsystemAffected', 'total_injuries', 'ElectricalLoadSpike']].head())\n",
        "\n",
        "print(\"\\nDescriptive statistics for 'ElectricalLoadSpike' column:\")\n",
        "display(combined_df['ElectricalLoadSpike'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6533393"
      },
      "source": [
        "## Add RootCauseCategory Column\n",
        "\n",
        "### Subtask:\n",
        "Create the `RootCauseCategory` column as a categorical variable (Human, Mechanical, Weather, ATC, Unknown) in the `combined_df` DataFrame. Values will be determined by analyzing keywords in 'Assessments_Contributing Factors / Situations', 'Assessments.1_Primary Problem', and narrative fields. If no clear category is found, it will default to 'Unknown'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cb5237b"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the first instruction of the subtask, I need to initialize the new `RootCauseCategory` column in `combined_df` with the default value 'Unknown'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914046bb"
      },
      "source": [
        "print(\"Initializing 'RootCauseCategory' column with 'Unknown'...\")\n",
        "combined_df['RootCauseCategory'] = 'Unknown'\n",
        "print(\"Initialization complete.\")\n",
        "print(\"First 5 rows with 'RootCauseCategory' column:\")\n",
        "display(combined_df[['Assessments_Contributing Factors / Situations', 'Assessments.1_Primary Problem', 'Report 1_Narrative', 'Report 1.2_Synopsis', 'RootCauseCategory']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844a1782"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the second instruction of the subtask, I need to define the `root_cause_keywords` dictionary with categories and their associated keywords.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4493a550"
      },
      "source": [
        "print(\"Defining root cause keywords...\")\n",
        "\n",
        "root_cause_keywords = {\n",
        "    'Human': ['human error', 'pilot error', 'controller error', 'fatigue', 'distraction', 'procedure violation', 'lack of training', 'crew coordination'],\n",
        "    'Mechanical': ['mechanical failure', 'engine failure', 'structural failure', 'component failure', 'system malfunction', 'equipment fault', 'maintenance error', 'gear malfunction'],\n",
        "    'Weather': ['weather', 'wind shear', 'turbulence', 'icing', 'thunderstorm', 'fog', 'visibility', 'crosswind', 'microburst'],\n",
        "    'ATC': ['air traffic control', 'atc instruction', 'controller action', 'clearance', 'vectoring', 'airspace violation'],\n",
        "    'Unknown': [] # Default, will be used if no other category matches\n",
        "}\n",
        "\n",
        "print(\"Root cause keywords defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c07fd085"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `root_cause_keywords` dictionary is defined, I need to define the `identify_root_cause` function as specified in the instructions (step 3). This function will process the narrative and assessment columns to determine the root cause category.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35b52c6c"
      },
      "source": [
        "print(\"Defining function to identify root cause...\")\n",
        "\n",
        "def identify_root_cause(row):\n",
        "    # Combine relevant text fields for keyword search\n",
        "    text_to_search = (\n",
        "        str(row['Assessments_Contributing Factors / Situations']).lower() + \" \" +\n",
        "        str(row['Assessments.1_Primary Problem']).lower() + \" \" +\n",
        "        str(row['Report 1_Narrative']).lower() + \" \" +\n",
        "        str(row['Report 1.2_Synopsis']).lower()\n",
        "    )\n",
        "\n",
        "    for category, keywords in root_cause_keywords.items():\n",
        "        if category == 'Unknown': # Skip the 'Unknown' category itself for keyword matching\n",
        "            continue\n",
        "        for keyword in keywords:\n",
        "            if keyword in text_to_search:\n",
        "                return category\n",
        "    return 'Unknown'\n",
        "\n",
        "print(\"Function 'identify_root_cause' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d22021f7"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `identify_root_cause` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to populate the `RootCauseCategory` column, and then display its value counts as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "079d1a78"
      },
      "source": [
        "print(\"Applying 'identify_root_cause' function to populate 'RootCauseCategory' column...\")\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before adding a new column\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to populate the 'RootCauseCategory' column\n",
        "combined_df['RootCauseCategory'] = combined_df.apply(identify_root_cause, axis=1)\n",
        "\n",
        "print(\"'RootCauseCategory' column populated.\")\n",
        "\n",
        "print(\"\\nValue counts for 'RootCauseCategory' column:\")\n",
        "display(combined_df['RootCauseCategory'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcf214c2"
      },
      "source": [
        "## Add SeverityScore Column\n",
        "\n",
        "### Subtask:\n",
        "Create the `SeverityScore` column as a numerical value between 1 and 5. This score will be calculated based on a weighted combination of `total_injuries`, `EventType`, and potentially other factors to represent the overall severity of the event. Events with higher `total_injuries` or more severe `EventType` will receive higher scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f24f186"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to initialize the new `SeverityScore` column in `combined_df` with a default numerical value of 1, as per the first instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25541f7b"
      },
      "source": [
        "print(\"Initializing 'SeverityScore' column with a default value of 1...\")\n",
        "combined_df['SeverityScore'] = 1\n",
        "print(\"Initialization complete.\")\n",
        "print(\"First 5 rows with 'SeverityScore' column:\")\n",
        "display(combined_df[['total_injuries', 'EventType', 'SeverityScore']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19f7118b"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the subtask instructions, I will define a mapping for `EventType` to assign a base severity score. This mapping will be a dictionary where common event types are assigned a base score, and a default will be used for others.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83b34338"
      },
      "source": [
        "# Task\n",
        "## Define EventType Severity Mapping\n",
        "\n",
        "### Subtask:\n",
        "Define a dictionary `event_type_severity_map` to assign a base severity score (e.g., 1-5) to different `EventType` categories. This mapping will be used to help calculate the `SeverityScore`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33c429df"
      },
      "source": [
        "## Define EventType Severity Mapping\n",
        "\n",
        "### Subtask:\n",
        "Define a dictionary `event_type_severity_map` to assign a base severity score (e.g., 1-5) to different `EventType` categories. This mapping will be used to help calculate the `SeverityScore`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "711a1f7e"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `event_type_severity_map` dictionary, including common EventType categories and their corresponding severity scores, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "198cb67e"
      },
      "source": [
        "print(\"Defining event_type_severity_map...\")\n",
        "\n",
        "event_type_severity_map = {\n",
        "    'ACC': 5, # Accident\n",
        "    'INC': 3, # Incident\n",
        "    'NMR': 4, # Near Midair Collision\n",
        "    'OTH': 1, # Other (default low severity)\n",
        "    'SYF': 4, # System Failure\n",
        "    'HAL': 3, # Hard Landing\n",
        "    'DFC': 2, # Damage to Aircraft\n",
        "    'ALT': 2, # Altimeter Setting Error\n",
        "    'FOD': 2, # Foreign Object Damage\n",
        "    'NAV': 3, # Navigation Error\n",
        "    'FLC': 3, # Flight Control Issue\n",
        "    'ENG': 4, # Engine Issue\n",
        "    'LGA': 3  # Landing Gear Anomaly\n",
        "}\n",
        "\n",
        "print(\"event_type_severity_map defined.\")\n",
        "print(\"Event Type Severity Map:\")\n",
        "display(event_type_severity_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9fb827c"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `event_type_severity_map` is defined, I will define a function `calculate_severity_score` that combines the base severity from `EventType` with the `total_injuries` to produce a final `SeverityScore` between 1 and 5, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9512ba03"
      },
      "source": [
        "print(\"Defining function to calculate SeverityScore...\")\n",
        "\n",
        "def calculate_severity_score(row):\n",
        "    # Get base severity from EventType, default to 1 if not in map\n",
        "    event_type_base_severity = event_type_severity_map.get(row['EventType'], 1)\n",
        "\n",
        "    # Ensure total_injuries is numeric, handle potential NaNs\n",
        "    total_injuries = pd.to_numeric(row['total_injuries'], errors='coerce')\n",
        "    if pd.isna(total_injuries):\n",
        "        total_injuries = 0 # Default to 0 if total_injuries is NaN\n",
        "\n",
        "    # Normalize total_injuries to a small range to avoid excessive influence\n",
        "    # Max possible total_injuries is 268 based on describe() from earlier, but let's use a dynamic max\n",
        "    max_total_injuries_in_df = combined_df['total_injuries'].max()\n",
        "    if max_total_injuries_in_df == 0:\n",
        "        normalized_injuries = 0\n",
        "    else:\n",
        "        normalized_injuries = (total_injuries / max_total_injuries_in_df) * 2 # Scale to max 2 for impact\n",
        "\n",
        "    # Combine scores. We want a score between 1 and 5.\n",
        "    # A simple linear combination or weighted average can work.\n",
        "    # Let's give more weight to event_type_base_severity initially\n",
        "    combined_score = (event_type_base_severity * 0.7) + (normalized_injuries * 0.3)\n",
        "\n",
        "    # Clip the score to be between 1 and 5\n",
        "    return np.clip(combined_score, 1, 5)\n",
        "\n",
        "print(\"Function 'calculate_severity_score' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd03022d"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `calculate_severity_score` function is defined, I need to apply this function to each row of the `combined_df` DataFrame to populate the `SeverityScore` column, as per the subtask instructions. After applying, I will display the first few rows of the DataFrame showing the new column and its descriptive statistics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbb97b1"
      },
      "source": [
        "print(\"Applying 'calculate_severity_score' function to populate 'SeverityScore' column...\")\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before adding a new column\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to populate the 'SeverityScore' column\n",
        "combined_df['SeverityScore'] = combined_df.apply(calculate_severity_score, axis=1)\n",
        "\n",
        "print(\"'SeverityScore' column populated.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with 'SeverityScore' column:\")\n",
        "display(combined_df[['EventType', 'total_injuries', 'SeverityScore']].head())\n",
        "\n",
        "print(\"\\nDescriptive statistics for 'SeverityScore' column:\")\n",
        "display(combined_df['SeverityScore'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4791d9f4"
      },
      "source": [
        "## Add IsCriticalEvent Column\n",
        "\n",
        "### Subtask:\n",
        "Create the 'IsCriticalEvent' column (Yes or No) based on predefined criteria, including `SeverityScore`, `total_injuries`, and `EventType`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cd08e7"
      },
      "source": [
        "**Reasoning**:\n",
        "As per the first instruction of the subtask, I need to initialize the new 'IsCriticalEvent' column in `combined_df` with the default value 'No' for all rows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf94d90f"
      },
      "source": [
        "print(\"Initializing 'IsCriticalEvent' column with 'No'...\")\n",
        "combined_df['IsCriticalEvent'] = 'No'\n",
        "print(\"Initialization complete.\")\n",
        "print(\"First 5 rows with 'IsCriticalEvent' column:\")\n",
        "display(combined_df[['SeverityScore', 'total_injuries', 'EventType', 'IsCriticalEvent']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97af695"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I need to define the criteria for what constitutes a 'Critical Event' and then apply these criteria to update the `IsCriticalEvent` column in the `combined_df`. This involves checking the `SeverityScore`, `total_injuries`, and `EventType` as per the instructions (step 2 and 3).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b731827a"
      },
      "source": [
        "print(\"Defining and applying criteria for 'IsCriticalEvent'...\")\n",
        "\n",
        "def determine_critical_event(row):\n",
        "    is_critical_score = row['SeverityScore'] >= 4\n",
        "    is_critical_injuries = row['total_injuries'] > 5\n",
        "\n",
        "    # High-severity EventTypes\n",
        "    high_severity_event_types = ['ACC', 'NMR', 'SYF']\n",
        "    is_critical_event_type = row['EventType'] in high_severity_event_types\n",
        "\n",
        "    if is_critical_score or is_critical_injuries or is_critical_event_type:\n",
        "        return 'Yes'\n",
        "    return 'No'\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before applying\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to update the 'IsCriticalEvent' column\n",
        "combined_df['IsCriticalEvent'] = combined_df.apply(determine_critical_event, axis=1)\n",
        "\n",
        "print(\"'IsCriticalEvent' column updated based on criteria.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with updated 'IsCriticalEvent' column:\")\n",
        "display(combined_df[['SeverityScore', 'total_injuries', 'EventType', 'IsCriticalEvent']].head())\n",
        "\n",
        "print(\"\\nValue counts for 'IsCriticalEvent' column:\")\n",
        "display(combined_df['IsCriticalEvent'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637fd2f9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `row['EventType']` could be `pd.NA`, leading to a `TypeError` when checked for membership in `high_severity_event_types`. To fix this, I will explicitly check if `EventType` is `pd.NA` and treat it as `False` for the critical event condition; otherwise, I will proceed with the membership check.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5d22a12"
      },
      "source": [
        "print(\"Defining and applying criteria for 'IsCriticalEvent'...\")\n",
        "\n",
        "def determine_critical_event(row):\n",
        "    is_critical_score = row['SeverityScore'] >= 4\n",
        "    is_critical_injuries = row['total_injuries'] > 5\n",
        "\n",
        "    # High-severity EventTypes\n",
        "    high_severity_event_types = ['ACC', 'NMR', 'SYF']\n",
        "\n",
        "    # Handle potential pd.NA in 'EventType'\n",
        "    event_type = row['EventType']\n",
        "    if pd.isna(event_type):\n",
        "        is_critical_event_type = False\n",
        "    else:\n",
        "        is_critical_event_type = event_type in high_severity_event_types\n",
        "\n",
        "    if is_critical_score or is_critical_injuries or is_critical_event_type:\n",
        "        return 'Yes'\n",
        "    return 'No'\n",
        "\n",
        "# De-fragment the DataFrame to avoid PerformanceWarning before applying\n",
        "# This line was already executed and dataframe copied, but kept for robustness if cell is run independently\n",
        "combined_df = combined_df.copy()\n",
        "\n",
        "# Apply the function to each row to update the 'IsCriticalEvent' column\n",
        "combined_df['IsCriticalEvent'] = combined_df.apply(determine_critical_event, axis=1)\n",
        "\n",
        "print(\"'IsCriticalEvent' column updated based on criteria.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with updated 'IsCriticalEvent' column:\")\n",
        "display(combined_df[['SeverityScore', 'total_injuries', 'EventType', 'IsCriticalEvent']].head())\n",
        "\n",
        "print(\"\\nValue counts for 'IsCriticalEvent' column:\")\n",
        "display(combined_df['IsCriticalEvent'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c531f090"
      },
      "source": [
        "## Summarize New Columns\n",
        "\n",
        "### Subtask:\n",
        "Display the first few rows of the DataFrame with the newly added columns to verify their creation and provide summary statistics (head, info, describe) for these new columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f58bc9e"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will display the first 5 rows of the `combined_df` DataFrame, explicitly showing the newly created columns: `SubsystemAffected`, `PhaseOfFlight`, `SensorWarning`, `HydraulicPressureDrop`, `EngineTempDeviation`, `ElectricalLoadSpike`, `RootCauseCategory`, `SeverityScore`, and `IsCriticalEvent` to verify their creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83dc5114"
      },
      "source": [
        "print(\"Displaying the first 5 rows with the newly added columns:\")\n",
        "display(combined_df[[\n",
        "    'SubsystemAffected', 'PhaseOfFlight', 'SensorWarning',\n",
        "    'HydraulicPressureDrop', 'EngineTempDeviation', 'ElectricalLoadSpike',\n",
        "    'RootCauseCategory', 'SeverityScore', 'IsCriticalEvent'\n",
        "]].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7811af7b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will print the information about the `combined_df` DataFrame using the `.info()` method to show data types and non-null counts for all columns, as requested by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0704408"
      },
      "source": [
        "print(\"\\nInformation about the combined_df DataFrame:\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbb260d3"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will display descriptive statistics for all columns in the `combined_df` DataFrame using the `.describe(include='all')` method to include both numerical and object type columns, as requested by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daa5e70e"
      },
      "source": [
        "print(\"\\nDescriptive statistics for all columns:\")\n",
        "display(combined_df.describe(include='all'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7ee0fd"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize all new columns added and their derivation methods, along with any insights gained from their initial review.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bea2a81a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **How was the `event_type_severity_map` defined?**\n",
        "    The `event_type_severity_map` was defined as a dictionary assigning integer severity scores (ranging from 1 to 5) to various `EventType` abbreviations. For instance, 'ACC' (Accident) was assigned a severity of 5, 'INC' (Incident) a severity of 3, and 'OTH' (Other) a severity of 1.\n",
        "\n",
        "2.  **How was the `SeverityScore` calculated?**\n",
        "    The `SeverityScore` was calculated using a custom function that combined the base severity from the `event_type_severity_map` (weighted 70%) with a normalized value of `total_injuries` (weighted 30%). The `total_injuries` were normalized by scaling them against the maximum injuries observed in the dataset. The final score was then clipped to be between 1 and 5.\n",
        "\n",
        "3.  **How was the `IsCriticalEvent` column determined?**\n",
        "    The `IsCriticalEvent` column was determined by evaluating three criteria:\n",
        "    *   `SeverityScore` greater than or equal to 4.\n",
        "    *   `total_injuries` greater than 5.\n",
        "    *   `EventType` being one of 'ACC', 'NMR', or 'SYF' (Accident, Near Midair Collision, System Failure).\n",
        "    If any of these conditions were met, `IsCriticalEvent` was set to 'Yes'; otherwise, it was 'No'. The calculation also robustly handled potential missing `EventType` values.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `event_type_severity_map` successfully assigns base severity scores to 13 different `EventType` categories, with 'ACC' having the highest base severity of 5 and 'OTH' having the lowest of 1.\n",
        "*   The calculated `SeverityScore` ranges from 1.0 to 4.1, with a mean of approximately 1.40, indicating that most events tend to have lower severity scores.\n",
        "*   The `IsCriticalEvent` column classifies 7,381 events as 'Yes' (critical) and 38,736 events as 'No' (non-critical) out of 46,117 total events.\n",
        "*   All newly added columns (`SubsystemAffected`, `PhaseOfFlight`, `SensorWarning`, `HydraulicPressureDrop`, `EngineTempDeviation`, `ElectricalLoadSpike`, `RootCauseCategory`, `SeverityScore`, `IsCriticalEvent`) have been successfully created and contain 46,117 non-null entries, ensuring no missing data in these new features.\n",
        "*   The `SensorWarning` column is a binary flag (0 or 1) with a mean of approximately 0.68, suggesting about 68% of events are associated with a sensor warning.\n",
        "*   Categorical columns like `SubsystemAffected`, `PhaseOfFlight`, and `RootCauseCategory` frequently show 'Other/Unknown', 'Taxi', and 'Unknown' respectively as their most common categories.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The predominance of 'Unknown' or 'Other/Unknown' categories in key descriptive columns like `RootCauseCategory`, `SubsystemAffected`, and `PhaseOfFlight` suggests that further data collection or categorization efforts could greatly enhance the granularity and utility of these features for more precise analysis.\n",
        "*   Given the successful creation of `SeverityScore` and `IsCriticalEvent`, these new metrics can now be leveraged as primary targets or predictors for advanced analytics, such as identifying risk factors, predicting future critical events, or optimizing resource allocation for safety improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df2420c5"
      },
      "source": [
        "print(\"Value counts for 'SubsystemAffected' column:\")\n",
        "display(combined_df['SubsystemAffected'].value_counts(dropna=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvXmG8tU762Q"
      },
      "source": [
        "print(\"Non-null counts for 'Report 1_Narrative' and 'Report 1.2_Synopsis':\")\n",
        "print(combined_df[['Report 1_Narrative', 'Report 1.2_Synopsis']].count())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f888c2a"
      },
      "source": [
        "print(\"Value counts for 'IsCriticalEvent' column:\")\n",
        "display(combined_df['IsCriticalEvent'].value_counts(dropna=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bb7b34"
      },
      "source": [
        "print(\"Value counts for 'SeverityScore' column:\")\n",
        "display(combined_df['SeverityScore'].value_counts(dropna=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c96c960d"
      },
      "source": [
        "print(\"\\nInformation about the combined_df DataFrame:\")\n",
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45cc16fe"
      },
      "source": [
        "print(\"\\nDescriptive statistics for all columns:\")\n",
        "display(combined_df.describe(include='all'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the combined dataframe into a csv file to be loaded into the sql server for further processing\n"
      ],
      "metadata": {
        "id": "h3vMPsH-Do-i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd3dea83"
      },
      "source": [
        "print(\"Saving 'combined_df' to 'source_file.csv'...\")\n",
        "combined_df.to_csv('source_file.csv', index=False)\n",
        "print(\"'combined_df' successfully saved to 'source_file.csv'.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7c157c2"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading 'source_file.csv'...\")\n",
        "files.download('source_file.csv')\n",
        "print(\"Download initiated. Please check your browser's download folder.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}